{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxDghGv2PCmoqpZnaHDbHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaojieTao/UCLA-ECE209AS-2022F/blob/main/gridworld.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0vJT5FHZTpb"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now start running the cells sequentially (by `ctrl + enter` or `shift + enter`) to avoid unnecessary errors by skipping some cells. \n",
        "\n",
        "## Section 1: Westwood Gridworld Environment\n",
        "\n",
        "In this section, we build the Westwood Gridworld environment, with which we can solve using MDP in Section 2.\n",
        "\n",
        "Every Westwood Gridworld environment should contain the following attributes:\n",
        "\n",
        "1. `env.action_space`\n",
        "2. `env.observation_space`\n",
        "3. `env.P` The transition probabilities matrix. "
      ],
      "metadata": {
        "id": "P47N_qyPans1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Action Space\n",
        "# - 0: LEFT\n",
        "# - 1: DOWN\n",
        "# - 2: RIGHT\n",
        "# - 3: UP\n",
        "# - 4: WAIT\n",
        "LEFT = 0\n",
        "DOWN = 1\n",
        "RIGHT = 2\n",
        "UP = 3\n",
        "WAIT = 4\n",
        "\n",
        "# Define WestwoodGridworld class.\n",
        "class WestwoodGridworld:\n",
        "    def __init__(self):\n",
        "        # Row and column size of the gridworld.\n",
        "        self.nrow = 5\n",
        "        self.ncol = 5\n",
        "\n",
        "        # Size of the action space and state space.\n",
        "        self.nA = 5\n",
        "        self.nS = self.nrow * self.ncol\n",
        "\n",
        "        # desc represents the map of the WestwoodGridworld.\n",
        "        # Row 0 through row 4.\n",
        "        self.desc=[\"PPPPW\", \"PBBPW\", \"PPDPW\", \"PBBPW\",\"PPSPW\"]\n",
        "        self.desc = np.asarray(self.desc, dtype=\"c\")\n",
        "\n",
        "        # Letter represents the nature of each state.\n",
        "        # 'D' = Diddy-Riese state\n",
        "        # 'S' = Saffron-Rose state\n",
        "        # 'W' = Westwood Boulevard state\n",
        "        # 'B' = Obstacle state\n",
        "        # 'P' = Pavement state\n",
        "\n",
        "\n",
        "        # Assign reward to each state.\n",
        "        self.rewardOfStates = {\n",
        "            b\"D\": 1.0,\n",
        "            b\"S\": 10.0,\n",
        "            b\"W\": -10.0,\n",
        "            b\"B\": 0,\n",
        "            b\"P\": 0\n",
        "        }\n",
        "\n",
        "        # pe: probability of noisy transition.\n",
        "        self.pe = 0.2\n",
        "\n",
        "        # P is the transition probabilities of each pair of state and action.\n",
        "        # For each pair of state and action, P[state][action] is a list of transitions,\n",
        "        # each transition is a list consists of prob, next_state, and reward.\n",
        "        self.P = {state: {action: [] for action in range(self.nA)} for state in range(self.nS)}\n",
        "\n",
        "        # Initialize the transition probabilities matrix P.\n",
        "        self.computeP()\n",
        "\n",
        "    # Compute the transition probabilities matrix P.        \n",
        "    def computeP(self):\n",
        "        for row in range(self.nrow):\n",
        "            for col in range (self.ncol):\n",
        "\n",
        "                # When the robot chooses to move, it has a chance of error pe.\n",
        "                s = self.to_s(row, col)\n",
        "\n",
        "                for a in range(4):\n",
        "                    li = self.P[s][a]\n",
        "                    dynamics = self.update_probability_matrix(row, col, a)\n",
        "                    \n",
        "                    # Append a list with prob, next_state, and reward.\n",
        "                    li.append(\n",
        "                        ((1-self.pe) * dynamics[0], dynamics[1], dynamics[2])\n",
        "                    )\n",
        "                    for b in [(a-1)%4, (a+1)%4, (a+2)%4, 4]:\n",
        "                        dynamics = self.update_probability_matrix(row, col, b)\n",
        "                        li.append(\n",
        "                        ((self.pe/4) * dynamics[0], dynamics[1], dynamics[2])\n",
        "                    )\n",
        "                        \n",
        "                # When the robot chooses to wait (the last action), it always end up waiting.\n",
        "                li = self.P[s][4]\n",
        "                dynamics = self.update_probability_matrix(row, col, 4)\n",
        "                li.append(\n",
        "                    (dynamics[0], dynamics[1], dynamics[2])\n",
        "                )\n",
        "\n",
        "    def to_s(self, row, col):\n",
        "        return row * self.ncol + col\n",
        "\n",
        "    def inc(self, row, col, a):\n",
        "        if self.desc[row, col] == b'B':\n",
        "            return (row, col)\n",
        "\n",
        "        ROW = row\n",
        "        COL = col\n",
        "\n",
        "        if a == LEFT: \n",
        "            col = max(col - 1, 0)\n",
        "        elif a == DOWN:\n",
        "            row = min(row + 1, self.nrow - 1)\n",
        "        elif a == RIGHT:\n",
        "            col = min(col + 1, self.ncol - 1)\n",
        "        elif a == UP:\n",
        "            row = max(row - 1, 0)\n",
        "\n",
        "        if self.desc[row, col] == b'B':\n",
        "            row = ROW\n",
        "            col = COL\n",
        "\n",
        "        return (row, col)\n",
        "\n",
        "    def update_probability_matrix(self, row, col, action):\n",
        "        newrow, newcol = self.inc(row, col, action)\n",
        "        newstate = self.to_s(newrow, newcol)\n",
        "        letter = self.desc[row, col]\n",
        "        newletter = self.desc[newrow, newcol]\n",
        "        reward = self.rewardOfStates[letter]\n",
        "        prob = 1.0\n",
        "\n",
        "        return prob, newstate, reward"
      ],
      "metadata": {
        "id": "l4uTyAATPSCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Compute Optimal Policy"
      ],
      "metadata": {
        "id": "vjU3W6oONK7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularRLTrainerAbstract:\n",
        "    \"\"\"This is the abstract class for tabular RL trainer. We will inherent the specify \n",
        "    algorithm's trainer from this abstract class, so that we can reuse the codes like\n",
        "    getting the dynamic of the environment (self._get_transitions()) \"\"\"\n",
        "    def __init__(self):\n",
        "        self.env = WestwoodGridworld()\n",
        "        self.action_dim = 5\n",
        "        self.obs_dim = 25\n",
        "\n",
        "    def _get_transitions(self, state, act):\n",
        "        \"\"\"Query the environment to get the transition probability, \n",
        "        the next state, and reward given a pair of state and action.\n",
        "        \"\"\"\n",
        "        transitions = self.env.P[state][act]\n",
        "        ret = []\n",
        "        for prob, next_state, reward in transitions:\n",
        "            ret.append({\n",
        "                \"prob\": prob,\n",
        "                \"next_state\": next_state,\n",
        "                \"reward\": reward\n",
        "            })\n",
        "        return ret\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Conduct one iteration of learning.\"\"\"\n",
        "        raise NotImplementedError(\"You need to override the \"\n",
        "                                    \"Trainer.train() function.\")"
      ],
      "metadata": {
        "id": "E8aWlV2gqbU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.1: Policy Iteration\n",
        "\n",
        "Recall the process of policy iteration: \n",
        "\n",
        "1. Update the state value function, given all possible transitions at current state of the environment.\n",
        "2. Find the best policy that earns highest value under current state value function.\n",
        "3. If the best policy is identical to the previous one then stop the training. Otherwise, return to step 1.\n",
        "\n",
        "In step 1, the way to update the state value function is by \n",
        "\n",
        "$$v_{k+1} = E_{s'}[r(s, a)+\\gamma v_{k}(s')]$$\n",
        "\n",
        "wherein the $a$ is given by current policy, $s'$ is next state, $r$ is the reward, $v_{k}(s')$ is the next state value given by the old (not updated yet) value function. The expectation is computed among all possible transitions (given a state and action pair, it is possible to have many different next states, since the environment is not deterministic).\n",
        "\n",
        "In step 2, the best policy is the one that takes the action with maximal expected return given a state:\n",
        "\n",
        "$$a = {argmax}_a E_{s'}[r(s, a) + \\gamma v_{k}(s')]$$\n",
        "\n",
        "Policy iteration algorithm has an outer loop (update policy, step 1 to 3) and an inner loop (fit the value function, within step 1). \n",
        "\n",
        "In each outer loop, we call once `trainer.train()`, where we call `trainer.update_value_function()` once to update the value function (the state value table). \n",
        "\n",
        "After that we call `trainer.update_policy()` to update the current policy. \n",
        "\n",
        "`trainer` object has a `trainer.policy` attribute, which is a function that takes observation as input and returns an action."
      ],
      "metadata": {
        "id": "N9RTdU6qtttH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyItertaionTrainer(TabularRLTrainerAbstract):\n",
        "    def __init__(self, gamma=1.0, eps=1e-10):\n",
        "        super(PolicyItertaionTrainer, self).__init__()\n",
        "        # discount factor\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # value function convergence criterion\n",
        "        self.eps = eps\n",
        "\n",
        "        # build the value table for each possible observation\n",
        "        self.table = np.zeros((self.obs_dim,))\n",
        "\n",
        "        # A random policy at the beginning.\n",
        "        self.policy = lambda x : 1\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Conduct one iteration of learning.\"\"\"\n",
        "\n",
        "        self.update_value_function()\n",
        "        self.update_policy()\n",
        "\n",
        "    def update_value_function(self):\n",
        "        while True:\n",
        "            old_table = self.table.copy()\n",
        "\n",
        "            for state in range(self.obs_dim):\n",
        "                act = self.policy(state)\n",
        "                transition_list = self._get_transitions(state, act)\n",
        "                \n",
        "                state_value = 0\n",
        "                for transition in transition_list:\n",
        "                    prob = transition['prob']\n",
        "                    reward = transition['reward']\n",
        "                    next_state = transition['next_state']\n",
        "                    state_value += prob * (reward+self.gamma*old_table[next_state])\n",
        "\n",
        "                # update the state value\n",
        "                self.table[state] = state_value\n",
        "\n",
        "            # Compare the old_table and current table to\n",
        "            # decide whether to break the value update process.\n",
        "            should_break = np.sum(np.abs((old_table)-(self.table))) < self.eps\n",
        "\n",
        "            if should_break:\n",
        "                break\n",
        "\n",
        "    def update_policy(self):\n",
        "        \"\"\"To define a new policy function, given current value function. \n",
        "        The best action for a given state is the one that has greatest expected return.\n",
        "\n",
        "        To optimize computing efficiency, we introduce a policy table,\n",
        "        which take state as index and return the action given a state.\n",
        "        \"\"\"\n",
        "        policy_table = np.zeros([self.obs_dim, ], dtype=np.int)\n",
        "\n",
        "        for state in range(self.obs_dim):\n",
        "            state_action_values = [0] * self.action_dim\n",
        "\n",
        "            # Assign the action with greatest \"value\"\n",
        "            # to policy_table[state]\n",
        "            for action in range(self.action_dim):\n",
        "                transitions_list = self._get_transitions(state, action)\n",
        "                state_action_value = 0\n",
        "                for transition in transitions_list:\n",
        "                    prob = transition['prob']\n",
        "                    reward = transition['reward']\n",
        "                    next_state = transition['next_state']\n",
        "                    state_action_value += prob*(reward+self.gamma*self.table[next_state])\n",
        "                state_action_values[action]=state_action_value\n",
        "            best_action = np.argmax(np.asarray(state_action_values))\n",
        "            policy_table[state] = best_action\n",
        "\n",
        "        self.policy = lambda obs: policy_table[obs]"
      ],
      "metadata": {
        "id": "VtlbPOaGtXoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Managing configurations of the experiments.\n",
        "default_pi_config = dict(\n",
        "    max_iteration=1000,\n",
        "    evaluate_interval=1,\n",
        "    gamma=0.8,\n",
        "    eps=1e-10\n",
        ")\n",
        "def policy_iteration(train_config=None):\n",
        "    config = default_pi_config.copy()\n",
        "    trainer = PolicyItertaionTrainer(gamma=config['gamma'], eps=config['eps'])\n",
        "\n",
        "    old_policy_result = {\n",
        "        obs: -1 for obs in range(trainer.obs_dim)\n",
        "    }\n",
        "\n",
        "    for i in range(config['max_iteration']):\n",
        "        # train the agent\n",
        "        trainer.train()\n",
        "\n",
        "        # Compare the new policy with old policy to check whether\n",
        "        #  should we stop. If new and old policy have same output given any\n",
        "        #  observation, them we consider the algorithm is converged and\n",
        "        #  should be stopped.\n",
        "        new_policy_result = {\n",
        "            obs: trainer.policy(obs) for obs in range(trainer.obs_dim)\n",
        "        }\n",
        "        should_stop = old_policy_result == new_policy_result\n",
        "        \n",
        "        if should_stop:\n",
        "            print(\"We found policy is not changed anymore at \"\n",
        "                  \"itertaion {}.\".format(i))\n",
        "            break\n",
        "        old_policy_result = new_policy_result\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "4llBu-Nwuc1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It may be confusing to call a trainer agent. But that's what we normally do.\n",
        "pi_agent = policy_iteration()"
      ],
      "metadata": {
        "id": "3yfWcsRXvqf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "harvest = pi_agent.table.reshape((5,5))\n",
        "harvest1 = np.around(harvest,1)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "# Plot the heatmap.\n",
        "im = ax.imshow(harvest, interpolation=\"nearest\")\n",
        "\n",
        "# Create colorbar.\n",
        "fig.colorbar(im, ax=ax)\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        text = ax.text(j, i, harvest1[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "ax.set_title(\"State-value heatmap:\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "9OjuZSiu8PXI",
        "outputId": "c3a22f0d-55f4-4b74-dc78-24ef682e36bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAAEICAYAAAD2l4mhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wUZf7A8c93N5UkEEIglITei4AgRYoowgkKNhQLVhQ99Xfeid5ZzlMRbGe/Qz2sWEEFKYIiUgQRkF4CSJMqhFSSEEjZfX5/7IIJKbuB7O7E/b5fr3mxM/PMs18mu9995plnZsQYg1JKWYEt0AEopdRJmpCUUpahCUkpZRmakJRSlqEJSSllGZqQlFKWoQnpD0REbhWRH31Qb1MRMSISUtV1K1WcJiRARPqKyE8iclREMkRkmYic515XqS+5fnkrR0Q+EJHxgY5DWUPQf2lEpCbwNfBn4HMgDOgH5AcyLqWCkbaQoDWAMeYzY4zDGHPcGPOdMWajiLQD3gJ6i0iuiGQBiMilIrJORLJFZL+IPFmsviXuf7Pc2/R2b3O7iGwVkUwRmSciTcoKRkTeFJEXT1s2U0QecL9+WER2iUiOiGwRkSvLqadUS01EFovIHcXmvYqpmBtFZJ+IpInIY8XqsRWLK11EPheRuGLrvxCRw+4W6BIR6eBePga4Efi7e1/Ndi/fIyIPichGETkmIu+KSIKIfOP+f38vIrU91e9e94GIvCUi893b/uDF/1MFijEmqCegJpAOTAaGALVPW38r8ONpywYAnXAl9HOAFOAK97qmgAFCipW/HNgJtMPVKv0n8FM58fQH9gPinq8NHAcauuevARq633skcAxocHqs5cSxGLjjDGI6WdfbQCTQGVcLsp17/f3ACiARCAf+B3xWbPvbgRj3uleB9cXWfQCMP+399rjrSwAaAUeAtUBXIAJYCDxRifpz3Ps1HHit+N8TV+v44UB/DnVy/z0CHYAVJveX8gPgAFAEzAIS3OtKJaQytn8VeMX9uqxE8A0wuti8DcgDmpRRlwD7gP7u+TuBhRW893rg8tNj9SIhVSamk3UlFlv2M3Cd+/VWYGCxdQ2AwuLvXWxdrLuuWu758hLSjcXmpwFvFpv/P2BGOfujrPqnFFsfDTiApEB/7nQqPekhG2CM2WqMudUYkwh0xNUCebW88iLSU0QWiUiqiBwF7gbiK3iLJsBrIpLlPuzLwJV4GonIo+7DlVwRecu4vjVTgOvd294AfFLsvW8WkfXF6uro4b0rHVMF2xwu9joP15f7ZF1fFatrK64vfYKI2EXkOffhXDauZIMXMacUe328jPloAC/r33/yhTEm1/1/bejh/VUAaEI6jTFmG65f1Y4nF5VR7FNcragkY0wtXP1MUkH5/cBdxpjYYlOkMeYnY8wzxpho93S3u/xnwAh3X0dPXC0E3PNvA/cBdYwxscDmYu9d3DH3vzWKLavvTUxl75kK7QeGnFZXhDHmIK6EejlwMVALV2sLKt5fleGpfoCkky9EJBqIA347y/dVPhD0CUlE2orIWBFJdM8n4WqdrHAXSQESRSSs2GYxQIYx5oSI9MD1pTgpFXACzYstewt4pFhnbi0Ruaa8mIwx64A04B1gnjEmy70qCtcXONVdz238njhPryMVOAiMcrcibgdanGlMHrwFTDjZWSwidUXkcve6GFz9Tem4kuMzp22bQsl9VVme6gcYKq6hHWHA08AKY8z+MsqpAAv6hISrw7MnsFJEjuFKRJuBse71C4Fk4LCIpLmX3QOME5Ec4F+4hgsAYIzJAyYAy9yHML2MMV8BzwNT3IcVm3F1oFfkU1y/+p8Wq3sL8BKwHNcXuROwrII67gQewvVl7QCcav2cYUzleQ1Xi/E79z5ZgWufAnwI7MWVHLfwe6I/6V2gvXtfzTiD9/ZUP7j24RO4DtW6AaNOrnCfuXv0DN5X+cDJMzlK/SGJyAfAAWPMPwMdi/JMW0hKKcsI+pHaSqmzJyJ7cHV/OIAiY0x39+DYqbhONOwBrjXGZFZYjx6yKaXOljshdTfGpBVb9gKukz/PicjDuAYd/6OievSQTSnlK5fjugIC979XeNrAJy2k0PAoE16jtueCFiCOQEdQSWWNOLIwY68+Adsyj3kuZBEnOEaByT+rnfunC6NMeoZ3X4A1G/OTgRPFFk0yxkw6OSMivwKZuIal/M8YM0lEstxj5RARATJPzpfHJ31I4TVq0+XC+31RdZULya1eGak6fcEBCqPtgQ7Ba1HTVgY6BK+tNAvOuo70DAc/z2vsVVl7gx0njDHdKyjS1xhzUETqAfNFZFvxlcYYIyIeWz/aqa1UkDKAE2fV1OUalY8x5oiIfAX0AFJEpIEx5pCINMB1kXSFtA9JqSBlMBQah1dTRUQkSkRiTr4GBuMaaDsLuMVd7BZgpqeYtIWkVBCrohZSAq6Lq8GVUz41xnwrIquAz0VkNK7R9Nd6qkgTklJBymBwVMFJLWPMblz3yDp9eTowsDJ1aUJSKog5z/pmC1VLE5JSQcoADk1ISimr0BaSUsoSDFBosUvHNCEpFaQMRg/ZlFIWYcBhrXykCUmpYOUaqW0tmpCUClqCw2JXa2tCUipIuTq1NSEppSzANQ5JE5JSyiKc2kJSSlmBtpC8cM2l5zJs0DkIwqzvN/LF12tKlbl/9EX0Prc5J/KLeOa/c9m+2+NtVnwmOiqchx4YQrOmdTHG8PxLc9my9feHokZHh/OPsZfSsEEsBQVFvPDyXH7dk1ZBjb6R1CiOJx4Zfmq+YYNY3vvoR76csfrUsj69WjL65n44nQaHw8l/Jy1gU/JBv8cKcO3Qcxk+8BwQmPX9Rj6fu7ZUma7tk7j/tgsJsds4mnOce5+YGoBIS2rdvQWv/zSBCde/ytJpZT0izmXcjH9Qv3k9xpwzttwyvmYQHBa7A5FXCUlELsH1MEA78I4x5jlfBNOscTzDBp3DnX//mKIiBy89fg0/rd7FwcNZp8r0OrcZSQ1qc92979ChdQMeHDOIMQ9/4otwvHLfPRfz86rdPPH0DEJCbESEh5ZYP+r689m5K4XHn5pO46Q47r9vMGP/McXvce4/mMEd930AgM0mfPnRPSz9aXuJMmvX72XZip0ANG9alycfvZybx7zj71BpnhTP8IHnMPoR1+fg5cdGsGzt7hKfg+ga4Tx458U8MOFLUtJyqF2zRgU1+ofNZuOO50ax5rsNFZbre2UPjueeqLCMv1jtkM1jehQROzAR11NN2wPXi0h7XwTTtFEcW7YfIr+gCIfTsG7Lfi7o1bpEmX49WvHt4mQAkrcfIjoqgjq1o3wRjkdRNcLp3CmJOd9uBKCoyEnusfwSZZo0rsPa9XsB2Lc/g/oJtagdG9gvz7ldmvDboSxSjmSXWH78ROGp15ERoQRqEG+TRnEk7yz5ORjQo1WJMoP7tuOHldtJScsBIDM7LxChlnD5/13Cj9NXkHXafi0uIiqCq/82jE8mTPNjZGUzCAXG7tXkL96013oAO40xu40xBcAUXE8TqHK796XRuX0iNaMjCA8Lofe5zakXH1OiTHxcNEfcH0KAI+k5xMdF+yIcjxrUr0VWVh4PP3gpb79xGw/9bQgRESVbSLt2H6F/3zYAtG3TgPoJtahbN6as6vxm4AXtWPDD1jLX9Tu/FR9OuoPnxo3g+Vfm+jkyl9370+jcttGpz8H5ZXwOkhrWJiYqgv8+OZL3nh/FJf198hvptToN4+h7RU9mv/ldheVufXokX748m/y8/ArL+YNrYKTNq8lfvHmnRsD+YvMH3MtKEJExIrJaRFYX5Z/Z0xv2Hszg469+5pUnruGlx0ew49cjOJ1WG0v6O7vdRutW9Zn59VruvOd9jp8o5IaRvUqU+XTqCqKjwnnnzdu46vJu7NiZgjOA4/VDQmyc37Mli5duK3P90p92cPOYd3hs3HRuv7mfn6Nz2Xswg49n/syrj4/glceuZvueIzidJfeZ3W6jTfMEHnx2On8bP43bRvQmqUHgnnRzzyu38s7DH1PRU3xadG5Kw+b1WTbjZz9GVjGHe3Ckp8lfqqxT2/1IlEkA0bUTz/gbN2fBJuYs2ATAmBv7kZqeU2J9WkZuiV/LenViSMvIPdO3OyupaTmkpuawddshAH5Yuq1UQsrLK+D5l35vaUz58M/8VqwvxN96dm/Ojl0pZGZVfIizcfMBGtaPpVbNSI5mH/dTdL/7euFmvl64GYC7ru9LanrJv3Fqeg5Hc45zIr+QE/mFrN96gJZN6rL/UIUPRq1Sw+/5E0PvuBiAGrVq8OhnfwWgVnxNzhvaFUeRg59mrjpVvl3v1rTu3pyPdk/EHmIntl4tXlz4JA9e9KTfYi7OGMFhql+n9kEgqdh8onuZT8TWqkHW0TwS4mO4oGcr7jqtw/rHVTu5ekhXvv9xGx1aNyA3L5/0AD1PKyPzGEdSs0lKjGP/gQy6dW3K3n3pJcpER4VzIr+QoiInlw7pzIZN+8nLKwhIvAADB7RnweKyD9caNYjl4CFXsmzVIoHQUHtAkhFA7Zo1yMx2fQ4G9GzFnY9+WmL9klU7GTt6IHabEBJip0PLBkwt44ysL816Yx6z3phXavlD793LijlrSiQjgK/f+o6v33Id0iU0qcvTsx8OWDI6yVkNT/uvAlqJSDNcieg64AZfBTThocupGROBw+Hk5be/Jzcvn8sHu27XO/O7DSxfs5ve5zZn6ht3ciK/kGf++42vQvHK6xPn88+HhxESYufQ4Syee3EOwy/tAsCsOetp3LgOjzx0GcYY9uxN44WXA9MvAxARHkr3rk156fVvTy0bPtQd69z19O/bhj8N7EhRkYOCgiKees7jQyJ8ZsKDw6kVE0lRkYMX31lAbl4+VwxyfQ5mzN/A3oMZrFi/hw9fuhXjNMxasJHd+/0/nMIbb639N3ef+1CgwyjF1altrZE/Xj25VkSGAq/iOu3/njFmQkXlo2snGn1QpG/ogyJ9p7o9KDLbZJzVh6FlpxrmpZmtPRcErmixYY2HB0VWCa/SozFmLhC4n3allE84LDYOyVrtNaWU31TbkdpKqT8mZzU8y6aU+gNyXVyrCUkpZQEGodCPl4V4QxOSUkHKGKrlwEil1B+SVMuBkUqpPyCDtpCUUhaindpKKUswSPW7QZtS6o/J9RikEK8mb4iIXUTWicjX7vlmIrJSRHaKyFQRCfNUhyYkpYKWd/dCqsT9kO4Hit9K4nngFWNMSyATGO2pAk1ISgUpg2uktjeTJyKSCFwKvOOeF+Ai4Et3kcnAFZ7q0T4kpYJYJVo/8SKyutj8JPdNGU96Ffg7cPLuiXWALGNMkXu+zDvNnk4TklJByhipzLVsaeXdfkRELgOOGGPWiMiAs4lJE5JSQcrVqV0ll470AYa775sWAdTE9di0WBEJcbeSvLrTrPYhKRW0XPfU9maqiDHmEWNMojGmKa47yi40xtwILAJGuIvdAni8BalPWkjGLuTXtNZFe+WJWR2YJ7MGi8NDGwc6BK/VjK8T6BC8Jpln//1ydWr7dBzSP4ApIjIeWAe862kDPWRTKohV9UhtY8xiYLH79W5cz3X0miYkpYKUFUdqa0JSKoj586m03tCEpFSQMgYKnZqQlFIW4Dpk04SklLKISozU9gtNSEoFKT+c9q80TUhKBS09ZFNKWYjeU1spZQmus2zWuqJCE5JSQUoHRiqlLEUP2ZRSlqBn2ZRSlqJn2ZRSlmCMUKQJSSllFXrIdprHbx9M3y7NyczO47p/fgjAX0b2p1+X5hQWOThw5Cjj3p1Hbl5+qW17d2rK2BsGYLPZmLlkE5PnrPJ3+HS7oC13P3kVNrvw7ZQVfPHGghLrQ8PsjH1lFK06JZKdmcez907myIEMv8dZHWJ94qbB9O/UnIycPK552vVZuGfY+VzQuQXGGDJy8nhi8jxSjx4rsV331kk8eM0Fp+ab1o/j4XfmsHjDLr/FntgygbGv30KLTklMfnYW096YX2H5P0+4lsE3nM+Vzf7qpwhLs2Ifksf2moi8JyJHRGSzLwL4+sdk/vLS9BLLVm7ey3WPTeaGxz9i3+FMbr209D2ebCL8/aaLuP/lr7j20Q8Y3LMtzRrG+SLEctlswr3jR/D4Lf/jroHPMWD4uTRulVCizOCRvcg9msfo/hOY8c5ibn9kmF9jrE6xzl6ezL3/KflZmDx/NSPHf8R1Ez5m6aZfGXNpr1Lbrd6+n+smfMx1Ez5mzCtfcqKgiBVb9vorbABysvJ489GpTHvje49lW3VuTHRsDT9E5ZnTiFeTv3hzAPkBcImvAli3/SDZx06UWLYyeS8OpwFg865DJMRFl9quQ/P67E/J4mDqUYocTuav3MYFXVv4Kswyte7ShN/2pHF4XzpFhQ5+mL2OXoM7lSjTe3Anvv/S1XJbOncDXfq08muMJ1WHWNfuPMjRvJKfhWMnCk69jgwLwZiK67j43FYsS/6VE4VFFResYkfTcti+fi+OIkeF5Ww24Y4nrubdp6ZXWM4fTo5DqlYJyRizBAjMMQYwvH8Hftq4p9TyurWjScnIOTWfkplL3doxpcr5Unz9WqT+lnlqPu1QFnUSapUoU6d+LdLcZZwOJ3k5J6hZO8qvcUL1ivV0917eh2+euZMhPdrx5uyfKiz7p+5t+HbVNj9FVnnDRl/IinkbyTiSHehQANc4JG8mf7FWF/tpbhvWgyKH4ZvlWz0XVn9YE2cuY8ijb/PNz1sZOaBLueXia0bRqlE8y5P9e7jmrbiEWvQffi4z31kU6FAA16UjRU6bV5O/VNk7icgYEVktIquLThzzvIEHl/VtT9/OzXn8f3PLXJ+amUtC3O8tooTa0aRm5pRZ1lfSDh+lbsPap+bjG8SSnnK0RJn0w0eJd5ex2W3UiIkgO/Ps909lVadYyzP3520M7Fr+YeSg7q1ZuH4nRU6nX+IZdvsFTFz4GBMXPkbcaa3NsrTslESDZnV5f+XTTF49gfDIMN5bOc4PkZav2h2yecsYM8kY090Y0z0k4uya+b07NeWmIecx9rWZ5BeU3Rew5dfDNE6IpWF8TULsNgb1bMuSdbvP6n0ra/uGfTRsFk9CUhwhoXYuGNaVFfNL9v2vmL+Zi0ecB0C/oZ3Z8NMOv8Z4UnWKtbjG9WJPvR7QuQV7UsrvPbike1u+XfWLP8ICYPZ7P3DvRRO496IJZJyW3Mvy8/ebuaHjP7il+2Pc0v0x8o8XcHvPf/kh0rJZsQ8p4Kf9x989lG5tE4mNjuTrl+9k0ozl3HppD8JC7Ex86GoANu06xHOTFxAfG8U/bxvMX1/5CofT8MLHi3j9waux24RZSzez+7d0v8budDh58/FpjP/obux2G99NXcm+7Ye56YEhbN+0j5Xzk5k3dQUPvTqKd5c8Rk5WHs/d96FfY6xOsT47eijdWrs+C98+eydvzV5O347NaJJQG6cxHMrIZsKnrqEK7RsnMKL/OYz72HV6vUGdmtSPi2HNjv1+jfmk2vVq8vp3j1AjJgLjNFwx5iLu6vsUebknGPfpfbz6t4+8Slr+Zix22l+Mh9MWIvIZMACIB1KAJ4wxFT7wLSo+ybS/7G9VFaNPxS/cF+gQ/tCq04MiE6ZvD3QIXlueOY2jhalnlU1i2tQ3Xd+4yauySy9+cY0xpvvZvJ83PLaQjDHX+zoIpZT/GWO9gZEBP2RTSgWK4NDHICmlrMJqfUiakJQKUla8lk0TklLByuDxUhx/04SkVBDTW9gqpSzBWLBT21rRKKX8yhjvpoqISISI/CwiG0QkWUSeci9vJiIrRWSniEwVkTBP8WhCUiqIGSNeTR7kAxcZYzoDXYBLRKQX8DzwijGmJZAJjPZUkSYkpYKUq/Vz9gnJuOS6Z0PdkwEuAr50L58MXOEpJk1ISgWxSlxcG3/ybh7uaUzxekTELiLrgSPAfGAXkGWMOXl1/AGgkad4tFNbqSBWidP+aRVdy2aMcQBdRCQW+ApoeybxaEJSKkgZBGcVn2UzxmSJyCKgNxArIiHuVlIicNDT9nrIplQQM15OFRGRuu6WESISCQwCtgKLgBHuYrcAMz3Foy0kpYKVqbJr2RoAk0XEjquR87kx5msR2QJMEZHxwDqgwtsWgSYkpYJbFVw6YozZCHQtY/luoPQzzCqgCUmpIBYUV/s77XAizlr/0fKkDqw+dzQEyI+tHvv1pALP9763DFO/bqBD8F5u6FlXYQCn01qfJ20hKRWsDBAMLSSlVPWgtx9RSlmHJiSllDV4deGsX2lCUiqYaQtJKWUJBoyeZVNKWYcmJKWUVeghm1LKMjQhKaUsQQdGKqWsRAdGKqWsQ8+yKaWsQrSFpJSyBG9uB+lnmpCUClqindpKKQvRFpJSyjKcgQ6gpIAnpHEjB9G/fXMycvO46t8fAfDnP/Xi6l6dyMzNA+D1uctYunVPqW1v7NeVq3t1RESYtmITHy9Z5/N4/3X7YPp2bk5mdh4jH/8QgL9c25/+XZpTWOTgwJGjPPXuPHKP55fYLizEztuPjCQ0xI7dLixYvYNJM5b7NNZx1xXbty+ctm+PufftnLL3bUxEOE9eN4hW9etgMPzrs/ls2HvIp/E+c/kgBrRuTvqxPIa94Yq3TUI8T102kBphYRzMyubB6d9wLL/Aq239pW5CTR6acDWxdaLBwNxpq5jxyYoSZUbc2oeLhnYGwB5iI6lZXUZe8Bw52cf9GmsJ1XEckogkAR8CCbj+C5OMMa9VVQAzV23hsx83MOGGP5VY/tEPa5m8eE2527WsX4ere3Xkhlc/o9Dh4K0xV/HDlt3sTztaVaGVafaPyUxdsJ5xd1xyatnK5L1M/HIpDqfh/67px22X9eA/XywtsV1BkYO7X/iC4/mF2O023n1kJD9t3MPm3b77ks/8+cz2LcA/rhrAsq17GPvB14TYbUSGnv0tUz2Zvn4LH/+8geev/D3eCcMH8fx3S1i19yBXd+3AHed347VFpRN5Wdv6i8PhZNJL37Jz6yEia4Tx3yl/Zu3yXezbnXqqzJcfLOPLD5YB0POCNlx10/mBTUZuVjvL5s1z2YqAscaY9kAv4F4RaV9VAazZfZCjeScqvV3zhDg27TvMicIiHE7D6l0HuLhTq6oKq1zrth8kO7dkvCuT9+Jwuv6ym3Ydol7t6DK3PZ5fCECI3UZIiA3j4wP4NbsPcvRY5fdtdEQY3Zo3YvrKzQAUOZzknMj3sNXZW733IEePl4y3aZ3arNrrer7gsl17Gdy+7L9xWdv6S0ZaLju3un5YjucVsP/XVOLr1Sy3/IVDzmHxNxv9FV7FquLBbFXIY0Iyxhwyxqx1v87B9QA4j8/oPlvX9+3MtAdHMW7kIGpGhpdav+NQOuc2a0StGhFEhIbQr11T6seWnQj8aXi/Dvy0aU+Z62wifPLUKOa/djcrk/eRvPuwf4Nzu75fZ6Y9NIpx15W9bxvF1SIz9zjjrx/M52Nv5MmRFxMZFpij+x2p6Qxs2wKASzq0pkHNmIDE4a2EhrG0aNuAbZsOlLk+PCKU7n1a8uP8LX6OrHqo1JNrRaQprucvrSxj3RgRWS0iqx3Hj51VUJ8v28jQCe8z4qWPSc0+xoPD+5cq8+uRDN5btIpJd13FW2OuZNvBVBwBHgd/+2U9cDgM3yzfWuZ6pzHc+MTHDH3gbTo0q0+LRnX8HKF7345/nxEvuvft5aX3rd1uo11iPaYu28i1L33C8YIiRg88z++xAjw28ztuOK8z08bcQFRYGAUOR0Di8EZEZBiPv3wdb73wDXnHym5R9rqgDcnr91nicA1ch2zeTP7idUISkWhgGvBXY0z26euNMZOMMd2NMd3tkVFnFVR6bh5OYzAGpq3YTMfG9css99XKZEa+8im3TvyC7OP57D2SeVbvezYu69Oevp2b889Jcz2WzT2ez+pt++ndqanvAztNiX27vOx9m5KVQ8rRHDbtc7Xg5m/YQbvEev4OFYDdaZmM/mg6V0/6lDmbt7E/07d9hGfKHmLj8ZevY+GcjSxbUH7r54JLOrH4m01+jKwCBtelI95MfuJVQhKRUFzJ6BNjzHTfhgTxMb8ntIGdWrDzcHqZ5eKiIwGoHxvDxZ1aMnftL74OrUy9Ozbl5iHn8cDrM8kvKCqzTGxMJNHuw6Pw0BB6dmjMnkMZ/gwTgPiaxfbtOS3Yeaj0vk3PyeNwVi5N69YGoGerJHYd9n+sAHFRrr+xCPy5f0+mrLZI38tpHnjqSvb/msr0j34qt0yN6HDO6d6UnxaV3YIOCIv1IXlzlk1wPZN7qzHm5aoO4PlRQzivZRKxURF8/687mDhvOee1SKJto7oYYziYkc24LxYAULdmFE+NHMQ9b88A4OVbhxFbI4Iip5MJ0xf6peN1wl1D6dY2kdjoSOa8dCeTZizn1kt7EBpqZ+KDVwOwedchnv1wAfGxUTx+22Duf+Ur4mtF8dQdl2CzCTYR5q/azo8bfvVprM/fVGzfPnEHE79dznktk2jbsC6Givfts9MW8dxNQwi12ziQfpTHP/vOp7ECvHT1EHo0TaJ2jQh+eOAO/rNoOTXCwrihh+t0+fytO5m2LhmAejFRjB8+iDGfzCh32y/dZX2tQ9fGXDysC7u3H+aNz+8B4P3X51OvQSwAc75YBUCfi9qz5qdd5B8v9Etc3rDaWTYxHvpdRKQvsBTYxO/DqB41xpR7bBKZkGRa3vhAlQXpS+GZFvuLeKBPrvWdptMD0wo8Eyt2vsvRvN/O6sMQnpRkEv/6N6/K7n5w7BpjTPezeT9veGwhGWN+xGo33lVKVQ2L/R4HfKS2Uiow/H0GzRuakJQKZha7QVulxiEppf5YqmIckogkicgiEdkiIskicr97eZyIzBeRHe5/a3uKRxOSUsGsak77l3d52cPAAmNMK2CBe75CmpCUClZeto48tZAquLzscmCyu9hk4ApPIWkfklLBzPtO7XgRWV1sfpIxZtLphU67vCzBGHPydhaHcd0xpEKakJQKYuL9DdrSPI1DOv3yMteYahdjjBHxfE5PD9mUUmetnMvLUkSkgXt9A+CIp3o0ISkVzKqgU7uCy8tmAbe4X98CzPQUjh6yKRWsqm5gZB/gJmCTiKx3L3sUeAc8GCkAABVKSURBVA74XERGA3uBaz1VpAlJqWBWBQnJw+VlAytTlyYkpYKZXjqilLICoVJn2fxCE5JSwUovrlVKWYomJKWUZQRDQnKGQl59i/1Py5H45b5Ah/CHtnV82Q9osKK8puU/S81qnPuqZgihHrIppaxDE5JSyhKMnmVTSlmJtpCUUlahfUhKKevQhKSUsgQ/P5XWG5qQlApSgh6yKaUsRBOSUso6NCEppSxDE5JSyhL0an+llKVoQlJKWYVeOqKUsgw9ZFNKWYMOjFRKWYompJIaxETz4qVDqFOjBgbD1A2b+GDNOoa0acVf+vSmZZ06XPXRp2w6nFJq2zC7nSk3jCTMbsduE779ZQevLVvu1/i7XdCWu5+8Cptd+HbKCr54Y0GJ9aFhdsa+MopWnRLJzszj2Xsnc+RAhl9jrA6xNqgRw8t9LyM+IgqD4bPtG3h/m+tR8re07cbNbc7FYZwsPLCL59YuLrFt85px/Lf/5afmk6JjeWXDUt7buhp/uXZ4Ny4bfA7GGHbvTePZ176hoNBxav2Qizpwz20DSE3PBWD6nLV8PX+T3+IrS7UcqS0iEcASINxd/ktjzBNVFUCR0/DMoh9ITjlCVFgoM28exY979rI9NZ17Zsxm/OCLy922wOFg1JQvyCssJMRmY+oNI/lh9x7WHzpUVeFVyGYT7h0/gkdvfJO0Q1m8NvsBVs7fzL4dvyfPwSN7kXs0j9H9J3DBsK7c/sgwnrt3sl/iq06xFhkn41cvJDkjhaiQMGZfditLD/1K3YgoBiW1Ysjs9yhwOqgTUaPUtruzMxj69fuu/6cIK0fcy7x92/0SN0B8XDRXDzuXm+59n4KCIp76+zAG9mvLNwuTS5Rb8OM2Xv3fgnJqCQxxWisjeXMfzHzgImNMZ6ALcImI9KqqAFKPHSM5xfXI72MFhexMTychOppdGRn8mpHpcfu8wkIAQmw2Quw2jB/boK27NOG3PWkc3pdOUaGDH2avo9fgTiXK9B7cie+/XAXA0rkb6NKnld/iK87qsaYeP0Zyhis5HisqYNfRdOrXiOHGNl15c/NyCpyu1kb6ibwK6+lTvwl7c7I4eCzb5zEXZ7fZCA8LwW4TIsJDScs45tf3PyPePkbbjznLYwvJGGOAXPdsqHvySYiNatakQ0I9Nhw67PU2NhFm3nwjTWrH8vG6DZXa9mzF169F6m+/J820Q1m06dKkRJk69WuR5i7jdDjJyzlBzdpRZGf69wNbnWJNjKpF+7h6rE/7jUe7XUiPekk81OUC8h1FTFizkI3p5f+NhzVrz6xft/gxWkjLyGXKjFV8+e5dFBQU8fO6Paxav6dUuQG9W9OlQxL7D2bwn3cXcSQtx69xlsVqh2xe3SlcROzuZ3YfAeYbY1ZWdSA1QkN544phPL1gMbkFBV5v5zSGYZM/ps+bb9O5QX1ax9ep6tCUH9UICeXNAVcybtUCcgsLsIuNWuGRXPHNhzyzZhET+19R7rahNhsXJ7Zk7t5tfowYoqPC6duzJSPvnMQVt75JZEQogwe0L1Fm2apdXHPHJG79ywesWr+XR/86xK8xlstiLSSvEpIxxmGM6QIkAj1EpOPpZURkjIisFpHVzmOV+0UNsdmYeMUwZm7Zync7dlZq25Ny8vNZvm8//Zs1PaPtz0Ta4aPUbVj71Hx8g1jSU46WKJN++Cjx7jI2u40aMRF+b3FA9Yg1RGy8NeBKZuxOPtUHdDgvh3l7fwFgQ/ohnBjiwiPL3H5AoxZszkghzcNhXVXr3qUJh1KOkpV9HIfDyQ/Ld9CxbcMSZbJzTlBY5Drs/Hr+Rtq0sMbTWMR4N/lLpZ6lYozJAhYBl5SxbpIxprsxprstKqpSQTx3yWB2pWfw3uq1ldouLjKSmPBwAMJDQujbpDG7Mvx3Bmv7hn00bBZPQlIcIaF2LhjWlRXzN5cos2L+Zi4ecR4A/YZ2ZsNPO/wWX3HVIdbnzx/Kzqx03t266tSy7/Zvp1d916Fls5jahNrsZOQfL3P74U3bMdvPh2sAR1Jz6NCmIeFhrh6Qbp0bs3d/eokydWr//p3o06Mlew+UXB8wFmsheXOWrS5QaIzJEpFIYBDwfFUF0K1RQ67s2J5tR1KZfcsoAF5auowwu51/XXwhcZGRvHP1FWw5ksptX0ynXnQUz/5pMKOnfUXd6Cj+PfQS7CLYRJjzy3YW7fq1qkLzyOlw8ubj0xj/0d3Y7Ta+m7qSfdsPc9MDQ9i+aR8r5yczb+oKHnp1FO8ueYycrDyeu+9Dv8VXnWLtXi+Rq1t0ZGvmEeZedhsAL6z7gc93buSF84cyb9hoCp0Oxi6bA0C9yGie7z2E2xZ+AUBkSCh9Gzbj0RXz/BbzSVu2H2Lxsu28++rNOBxOduw+wqx5Gxl9Qx+27TzMsp93MWLYufTp0RKHw0l2zgmeefUbv8dZigWfOiKuPusKCoicA0wG7LhaVJ8bY8ZVtE14YpJJ/MvfqixIX2r9X31QpC9VpwdFJn1pD3QIXlu/5DVysg7I2dQRXSfJdBzi3fd05Sdj1xhjup/N+3nDm7NsG4Guvg5EKRUAHhok3hKR94DLgCPGmI7uZXHAVKApsAe41hhT4Vieqnker1KqWqrCTu0PKN23/DCwwBjTCljgnq+QJiSlglUVDow0xiwBTj+jdDmu7h7c/5Y/ZsMt4NeyKaUCpxKd2vEiUvziwEnGmEketkkwxpy8juswkODpTTQhKRXEKpGQ0s6mU9sYY0Q8H/zpIZtSwcrg6tT2ZjozKSLSAMD97xFPG2hCUiqI+Xik9izgFvfrW4CZnjbQhKRUMKuiTm0R+QxYDrQRkQMiMhp4DhgkIjuAi93zFdI+JKWCVFXeoM0Yc305qwZWph5NSEoFK2Msd4M2TUhKBTNr5SNNSEoFM6vdoE0TklLBygB6yKaUsgxr5SNNSEoFMz1kU0pZhp5lU0pZQ7A8SlvCnUgT/95o/Uw1+yot0CFUyn8bVfkDX3xq9L6+gQ7Ba6tbnBPoELxWtPKsbhYJnBwYaa2MpC0kpYKZxe6prQlJqSCmLSSllDUESx+SUqo60GvZlFJWoodsSilLsOCDIjUhKRXMtIWklLIMa+UjTUhKBTNxWuuYTROSUsHKoAMjlVLWIBgdGKmUshBNSEopy9CEpJSyBO1DUkpZiZ5lU0pZhNFDNqWURRg0IZ2uQWRN/t1zOPERURhgyq61TN6xinaxCTzdfQhhthAcxskTa75lY8ZvZdYRHRLGt0PuZv7BX3hq7TyfxRoioTzQ5p+ESAg2sbMu82fmHJrOA60fJ9weAUBMSE325u3if7teLbFt6+h2XJ006tR8/YgGvLd7IhuOrvFZvABSdxE4j+HqLCjCpF8FUguJfQ3sjcBxEJP1FzDZpTeOuBKJvgcAk/sGnPjKZ3GGSAiPtHuEEFsIduyszlzNjIMzALgq8SrOizsPp3Gy6Mgivk/5vtT2cWFx3NbsNuLC4jAYXvnlFdIL0n0W77jrBtG/fXMycvO46oWPAPjzn3pxda9OZB5z3S319TnLWLp1T4ntmtatzb9vGXpqPrFOLSZ+s5yPl6zzWawVstYRm/cJSUTswGrgoDHmsqoKoMg4eXbD9yRnHiYqJIwZg0ezLOVX/tF5IK9vXsqSw7u4oEEL/tF5IDcu+qjMOv7aaQA/p+6rqpAqiLWQ17Y/Q74zHxt2xrZ9nOTsDby8/elTZe5s/hc2Zq0tte323K08u/UxAGrYo3iq40tsyd7k85gBTMZNYDJPzUvUXZiCn+DYJIga45rP/XfJjaQWEv1/mPQrAYPUmYHJX1B24qoCRaaIF7a9QL4zH7vYeaTdI2zM2kjDyIbEhcXx6MZHMRhiQmLK3P7O5ncy+7fZbMneQrgtHOPjayJm/ryFz37cwIQb/lRi+Uc/rGXy4vJ/ZPakZnLNi58AYBNhwZN3smDTTp/GWhGrjUOyVaLs/cDWqg4g9UQuyZmHAThWVMCu7DQSImMwxhAdGg5ATGgEKcdzyty+Q+36xEdE8ePh3VUdWpnynfkA2MWOXUJKXAsUYYukTUwHNmRV3OrpWrsHyUc3UGgKfBlq+SIGwnF3a+f4VxBxceky4f2gYBmYo64kVLAMwvv7NKzi+zZEXL+VF9a7kFkHZ51KMDlFpT8HDSMaYhMbW7K3nKqnwOnbfbtm90GOHjtxVnX0bJ3E/vSjHMos+7PtF8Z4N/mJVy0kEUkELgUmAA/4KphGNWrRPrY+G9IPMn7dd7x/wQ080uViBLh2weTScQGPdhnE2BUzOD+hma/COu09hYfbjadueAJLUuezJ2/XqXWdY7uxLSeZE87jFdbRvXYvFhz5xtehuhiDxL0PGEzeFDg+FWzx4Ex1rXemuuZPZ0vAOA79Xo3jMNgSfBqqIDzZ4UnqRdRjYcpCdh/bTb2IevSI68G5ceeSU5jDp3s/JSU/pcR2CREJ5DnyuK/lfcSHx7Mlewtf7P/C562kslzfrzPDz2tH8v4UXpy5hOzj+eWWHdK1Dd+s3ebH6E5jDDisdczmbQvpVeDvVHDEKSJjRGS1iKx2ZB+rdCA1QkKZ2GcE49d9R25RATe07MaE9fPpN/t1nlk/n2fPK32UOKpldxYf2snhclpPvmAwPLv1MR7b9BeaRrWgQUTiqXXd43qzOmN5hdvXDImlYWQSW47663Dtekz6FZjM0UiNGyH0vLJK+SUWTwyGJ5Kf4IH1D9AsuhmNIhsRIiEUmkLGJY9jSeoSbm9+e6nt7GKndXRrpu6fyrjkcdQNr0vfeP8/7eTzZRsZOv59Rrz4ManZx3jw8vJblCF2GwM6tOC79Tv8GGEZLNZC8piQROQy4IgxpsLjEGPMJGNMd2NMd3vNqEoFESI2Jp4/gll7N/PdwV8AuKrpOcw74Pr1mLt/K53rNCy1XZf4RG5q2Z3Fl93Hw10u5sqm5/DQORdW6r3P1HFHHr/kbKFDLdejc6Ls0TSJas7mo+sr3K5bXE82ZK3GicMfYYLT3ZpwZkD+fAg9B5xpYKvrWm6rC84yOn+dKYi9walZsdf/vS4fO+44zrbsbXSq1YnMgkzWZLg+emsy15AYmViqfEZBBvvy9pGan4oTJ2sz19IkqolfYi0uPTcPpzEYA9OWb6Zj4/rllu3XrilbDx4hPTfAjwurooQkIpeIyC8islNEHj7TcLxpIfUBhovIHmAKcJGIfHymb1iWZ3tcxs6cNN7b/vszx1JO5NKzrutD1bteU/bkZJTabuyKGfT/+j8M+Pq/PLf+e77as5F/b1xUlaGVEB0SQ6S9BgChEkq7mE4cPuE683du7R5sPrqeIlNYYR3da3tuRVUZiQSJ+v11WF8o2g75CyHyStfyyCvhxILS2+YvhbA+IDVdU1gf1zIfiQmJIdIeCbj2bYdaHTh04hBrM9fSrmY7ANrEtCHlROmk+OuxX6kRUuNUh3e7mu347XjZZ2R9Kb7YD/HAc1qw81D5Z/mGdG0b2MM1cI/UNt5NFXCf8JoIDAHaA9eLSPszCcljH5Ix5hHgEfcbDwAeNMaMqnCjSugWn8SVTc9hW1YKswbfAcBLmxbx2Ko5PN51MHabjXxHEY+tngNAx9oNuKHluTy6ak5VheC1WqGx3Nz0LmzYEBHWZK481SLqFteb7w7PLlG+cY1m9Ks7kE/2vgNAXFg8tcPi2JHrpw+iLR6JneieCcGcmA0FSzGFm1yn/SOvcZ/2v99dpCNS43pM9mNgjmKOvYHUmQ6AOTbR1cHtI7VCa3FH8zuwiQ1BWJWxig1ZG9ies527WtzF4PqDOeE8wfu/vg9A06imXFj3Qt7f8z4Gw9R9U3mo7UMIwp5je/gh9QefxQrw/E1DOK9lErFREXz/xB1M/HY557VMom3DuhgMBzOyGfeFK9HXrRnFUyMHcc/brmEMkWEh9G7TmHFflB6+4F8GTJX0IfUAdhpjdgOIyBTgcmBLZSsSU4njw2IJqcLT/hEtGpnEZ/5c2VgCYnDLAP9KVZI+udZ3Vn9WfZ5cu/PTlzmesv+sHl9bKyzBnF//eq/Kfrv/tb1A8cc8TzLGTAIQkRHAJcaYO9zzNwE9jTH3VTamSg2MNMYsBhZX9k2UUhblfYMkzRjT3ZehgAVGaiulAqhqzqAdBJKKzSe6l1VaZQZGKqX+ULw8w+Y5aa0CWolIMxEJA64DZp1JRNpCUipYGaAKbj9ijCkSkfuAeYAdeM8Yk3wmdWlCUiqYVdGgR2PMXGDu2dajCUmpoGW9S0c0ISkVrAyYqhmHVGU0ISkVzDyMwvY3TUhKBTOL3Q9JE5JSwcqYKjnLVpU0ISkVzLSFpJSyBoNx+Ok2OF7ShKRUsDp5+xEL0YSkVDDT0/5KKSswgNEWklLKEkyV3aCtymhCUiqIWa1Tu1J3jPS6UpFUYG8VVxtPyTvWWV11irc6xQrVK15fxdrEGFP3bCoQkW9xxeeNNGPMJWfzft7wSULyBRFZ7Y871lWV6hRvdYoVqle81SlWK9AbtCmlLEMTklLKMqpTQpoU6AAqqTrFW51iheoVb3WKNeCqTR+SUuqPrzq1kJRSf3CakJRSllEtEpKIXCIiv4jIThF5ONDxVERE3hORIyKyOdCxeCIiSSKySES2iEiyiNwf6JjKIyIRIvKziGxwx/pUoGPyhojYRWSdiHwd6FiqA8snJBGxAxOBIUB74HoRaR/YqCr0AeDzAWRVpAgYa4xpD/QC7rXwvs0HLjLGdAa6AJeISK8Ax+SN+4GtgQ6iurB8QgJ6ADuNMbuNMQXAFODyAMdULmPMEiAj0HF4wxhzyBiz1v06B9cXp1Fgoyqbccl1z4a6J0ufkRGRROBS4J1Ax1JdVIeE1AjYX2z+ABb90lRnItIU6AqsDGwk5XMf/qwHjgDzjTGWjdXtVeDvgLWuYLWw6pCQlI+JSDQwDfirMSY70PGUxxjjMMZ0wfXs+B4i0jHQMZVHRC4Djhhj1gQ6luqkOiSkg0BSsflE9zJVBUQkFFcy+sQYMz3Q8XjDGJMFLMLafXV9gOEisgdXN8NFIvJxYEOyvuqQkFYBrUSkmYiEAdcBswIc0x+CiAjwLrDVGPNyoOOpiIjUFZFY9+tIYBCwLbBRlc8Y84gxJtEY0xTXZ3ahMWZUgMOyPMsnJGNMEXAfMA9Xp+vnxpjkwEZVPhH5DFgOtBGRAyIyOtAxVaAPcBOuX+/17mlooIMqRwNgkYhsxPUjNd8Yo6fS/2D00hGllGVYvoWklAoempCUUpahCUkpZRmakJRSlqEJSSllGZqQlFKWoQlJKWUZ/w9YxQHGwhQRiwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VzM3ck9N_STP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}